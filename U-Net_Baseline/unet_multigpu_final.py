# -*- coding: utf-8 -*-
"""UNet_multigpu_final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uD9UrPXOP5COfmhh2wRNygEuW-BmxhBU
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split

# Hyperparameters
BATCH_SIZE  = 1
TARGET_SIZE = (224, 224)
EPOCHS      = 50  # adjust as needed

import os, zipfile, glob
import numpy as np

INPUT_ZIP  = '/content/drive/MyDrive/generated_input.zip'
OUTPUT_ZIP = '/content/drive/MyDrive/generated_target.zip'

def load_npy_from_zip(zip_path, extract_dir):
    os.makedirs(extract_dir, exist_ok=True)
    with zipfile.ZipFile(zip_path, 'r') as z:
        z.extractall(extract_dir)
    # now grab any .npy, even in sub‐folders
    pattern = os.path.join(extract_dir, '**', '*.npy')
    files = sorted(glob.glob(pattern, recursive=True))
    if not files:
        raise ValueError(f"No .npy files found in {extract_dir} after extracting {zip_path}")
    # load & stack
    return np.stack([np.load(f).astype('float32') for f in files], axis=0)

# usage
power_maps = load_npy_from_zip(INPUT_ZIP,  'power_maps')
temp_maps  = load_npy_from_zip(OUTPUT_ZIP, 'temp_maps')

# Subsample power_maps to match the number of samples in temp_maps
power_maps = power_maps[:temp_maps.shape[0]]

print("Loaded shapes:", power_maps.shape, temp_maps.shape)

# Slice channel 0 → shape becomes (N,224,224,1)
X = power_maps[..., 0:1]
Y = temp_maps[..., 0:1]

print("power_maps shape before creating dataset:", X.shape)
print("temp_maps shape before creating dataset:", Y.shape)

# 80% train / 20% test split
X_train, X_test, Y_train, Y_test = train_test_split(
    X, Y, test_size=0.2, random_state=42
)

print(f"Train samples: {X_train.shape[0]}, Test samples: {X_test.shape[0]}")

def make_ds(X, Y, batch_size=BATCH_SIZE, target_size=TARGET_SIZE):
    ds = tf.data.Dataset.from_tensor_slices((X, Y))
    ds = ds.map(
        lambda x, y: (
            tf.image.resize(x, target_size),
            tf.image.resize(y, target_size)
        ),
        num_parallel_calls=tf.data.AUTOTUNE
    )
    return ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)

train_ds = make_ds(X_train, Y_train)
test_ds  = make_ds(X_test,  Y_test)

from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, Concatenate
from tensorflow.keras.models import Model

def build_unet(input_shape=(224,224,1)):
    inputs = Input(shape=input_shape)
    # Encoder
    c1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)
    c1 = Conv2D(64, 3, activation='relu', padding='same')(c1)
    p1 = MaxPooling2D()(c1)

    c2 = Conv2D(128, 3, activation='relu', padding='same')(p1)
    c2 = Conv2D(128, 3, activation='relu', padding='same')(c2)
    p2 = MaxPooling2D()(c2)

    # Bottleneck
    c5 = Conv2D(512, 3, activation='relu', padding='same')(p2)
    c5 = Conv2D(512, 3, activation='relu', padding='same')(c5)

    # Decoder
    u6 = Conv2DTranspose(256, 2, strides=2, padding='same')(c5)
    merge6 = Concatenate()([u6, c2])
    c6 = Conv2D(256, 3, activation='relu', padding='same')(merge6)
    c6 = Conv2D(256, 3, activation='relu', padding='same')(c6)

    u7 = Conv2DTranspose(128, 2, strides=2, padding='same')(c6)
    merge7 = Concatenate()([u7, c1])
    c7 = Conv2D(128, 3, activation='relu', padding='same')(merge7)
    c7 = Conv2D(128, 3, activation='relu', padding='same')(c7)

    outputs = Conv2D(1, 1, activation='linear')(c7)
    return Model(inputs, outputs)

model = build_unet(input_shape=(TARGET_SIZE[0], TARGET_SIZE[1], 1))
model.summary()

model.compile(
    optimizer='adam',
    loss='mse',
    metrics=[tf.keras.metrics.MeanAbsoluteError(name='mae')]
)

import os
ckpt_dir = '/content/drive/MyDrive/multigpu_checkpoints'
os.makedirs(ckpt_dir, exist_ok=True)
ckpt_path = os.path.join(ckpt_dir, 'best_model.h5')

# 3) Callback to save only the best model (by val_mae)
checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(
    filepath=ckpt_path,
    monitor='val_mae',
    mode='min',
    save_best_only=True,
    verbose=1
)

import time
class TimeHistory(tf.keras.callbacks.Callback):
    def on_train_begin(self, logs=None):
        self.epoch_times = []
    def on_epoch_begin(self, epoch, logs=None):
        self._start_time = time.time()
    def on_epoch_end(self, epoch, logs=None):
        duration = time.time() - self._start_time
        self.epoch_times.append(duration)
        thru = X_train.shape[0] / duration
        print(f"→ Epoch {epoch:02d} took {duration:.2f}s, throughput {thru:.1f} samples/s")

time_cb = TimeHistory()

history = model.fit(
    train_ds,
    epochs=EPOCHS,
    validation_data=test_ds,
    callbacks=[checkpoint_cb, time_cb]
)

loss, mae = model.evaluate(test_ds)
print(f"Test loss (MSE): {loss:.4f}")
print(f"Test MAE   : {mae:.4f}")

import numpy as np

# 1) get raw predictions and ground-truth from the test set
y_pred = model.predict(test_ds)
y_true = np.concatenate([y for _, y in test_ds], axis=0)

# 2) compute mean absolute error in °C
abs_loss = np.mean(np.abs(y_pred - y_true))
print(f"Mean Absolute Error: {abs_loss:.4f} °C")

import time

# a) Warm-up
for x_batch, _ in test_ds.take(1):
    _ = model.predict(x_batch)

# b) Measure over the entire test set
start = time.time()
n = 0
for x_batch, _ in test_ds:
    n += x_batch.shape[0]
    _ = model.predict(x_batch)
elapsed = time.time() - start

throughput = n / elapsed
latency_ms = elapsed / n * 1000

print(f"Test set: {n} samples in {elapsed:.2f}s")
print(f"→ Throughput: {throughput:.2f} samples/s")
print(f"→ Avg latency: {latency_ms:.2f} ms/sample")

# A quick rule-of-thumb: ~2 × total trainable parameters
total_params = model.count_params()
flops_approx = 2 * total_params
print(f"Approximate FLOPs per inference: {flops_approx:,}")

import matplotlib.pyplot as plt

# Take one batch from the test dataset and plot input, truth, and prediction
for x_batch, y_batch in test_ds.take(1):
    # Run the model to get the prediction
    y_pred_batch = model.predict(x_batch)

    # Extract the single sample and its single channel
    input_power = x_batch[0, ..., 0]
    true_temp   = y_batch[0, ..., 0]
    pred_temp   = y_pred_batch[0, ..., 0]

    # Plot side-by-side
    fig, axes = plt.subplots(1, 3, figsize=(12, 4))
    for ax, img, title in zip(
        axes,
        [input_power, true_temp, pred_temp],
        ['Input Power', 'True Temp', 'Predicted Temp']
    ):
        ax.imshow(img, cmap='magma' if 'Power' in title else 'hot')
        ax.set_title(title)
        ax.axis('off')
    plt.tight_layout()
    plt.show()
    break

import os
import glob
import numpy as np
from collections import defaultdict

# ─── ASSUMES ───────────────────────────────────────────────────────────────────
# • You’ve already mounted your Drive and loaded your multi-GPU UNet into `model`.
# • Your inputs are *_inp.npy and targets are *_out.npy in the folders below.
# ────────────────────────────────────────────────────────────────────────────────

# Paths
drive_root    = "/content/drive/MyDrive"
inp_dir       = os.path.join(drive_root, "datasets/dataset_test/inputs")
gt_dir        = os.path.join(drive_root, "datasets/dataset_test/targets")
results_root  = os.path.join(drive_root, "AI_Temperature", "RESULTS_DAC", "multi_gpu_on_others")
gt_save_dir   = os.path.join(results_root, "gt")
pred_save_dir = os.path.join(results_root, "pred")
os.makedirs(gt_save_dir,   exist_ok=True)
os.makedirs(pred_save_dir, exist_ok=True)

heat_value    = 950.0
test_prefixes = ['ascend910', 'micro150']

# Get your UNet's expected input shape
_, H, W, C = model.input_shape  # e.g. (None, 224, 224, 1)

results = defaultdict(lambda: {'mae': [], 'rmse': [], 'r2': []})

def eval_sample_keras(model, inp_np, gt_np):
    # ─── build single-channel input ─────────────────────────────────────────────
    power = inp_np[..., 0].astype(np.float32)          # take only channel-0
    x     = power.reshape((1, H, W, 1))                # (1, H, W, 1)
    pred  = model.predict(x)[0, ..., 0]                # (H, W)
    # ─── prepare GT ─────────────────────────────────────────────────────────────
    gt = gt_np.astype(np.float32)
    if gt.ndim == 3:
        gt = gt[..., 0]                                # collapse to (H, W)
    # ─── compute metrics ────────────────────────────────────────────────────────
    mae   = np.mean(np.abs(pred - gt))
    rmse  = np.sqrt(np.mean((pred - gt)**2))
    ss_res= np.sum((pred - gt)**2)
    ss_tot= np.sum((gt   - gt.mean())**2)
    r2    = 1 - ss_res/ss_tot if ss_tot > 0 else np.nan
    return pred, gt, mae, rmse, r2

# ─── EVALUATION LOOP ────────────────────────────────────────────────────────────
for inp_path in sorted(glob.glob(os.path.join(inp_dir, "*_inp.npy"))):
    base = os.path.basename(inp_path)[:-4]  # e.g. "ascend910_00020_inp"
    if not any(base.startswith(p) for p in test_prefixes):
        continue

    gt_filename = base.replace("_inp", "_out") + ".npy"
    gt_path     = os.path.join(gt_dir, gt_filename)
    if not os.path.exists(gt_path):
        print(f"⚠️ missing GT for {base} (looking for {gt_filename})")
        continue

    inp_np = np.load(inp_path)
    gt_np  = np.load(gt_path)
    pred, gt, mae, rmse, r2 = eval_sample_keras(model, inp_np, gt_np)

    # save GT & prediction arrays
    np.save(os.path.join(gt_save_dir,   gt_filename),    gt)
    pred_filename = base.replace("_inp", "_pred") + ".npy"
    np.save(os.path.join(pred_save_dir, pred_filename), pred)

    # accumulate metrics
    prefix = next(p for p in test_prefixes if base.startswith(p))
    results[prefix]['mae'].append(mae)
    results[prefix]['rmse'].append(rmse)
    results[prefix]['r2'].append(r2)

# ─── PRINT RESULTS ──────────────────────────────────────────────────────────────
print("\n=== multi_gpu UNet tested on ascend910 & micro150 ===")
for p in test_prefixes:
    if results[p]['mae']:
        print(f"{p:12s} | MAE: {np.mean(results[p]['mae']):.4f}  "
              f"RMSE: {np.mean(results[p]['rmse']):.4f}  "
              f"R²: {np.mean(results[p]['r2']):.4f}")
    else:
        print(f"{p:12s} | no samples found")

all_mae  = np.hstack([results[p]['mae']  for p in test_prefixes if results[p]['mae']])
all_rmse = np.hstack([results[p]['rmse'] for p in test_prefixes if results[p]['rmse']])
all_r2   = np.hstack([results[p]['r2']   for p in test_prefixes if results[p]['r2']])
print(f"\nOverall   | MAE: {all_mae.mean():.4f}  "
      f"RMSE: {all_rmse.mean():.4f}  "
      f"R²: {all_r2.mean():.4f}")